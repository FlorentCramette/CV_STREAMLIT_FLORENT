import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error

# Configuration de la page
st.set_page_config(page_title="Projets - Analyse du March√© du Vin", layout="wide")

st.markdown(
    """
    <style>
        .block-container {
            max-width: 800px;  /* Ajuste cette valeur pour r√©duire la largeur */
            margin: auto;
        }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("üç∑ Analyse du March√© du Vin et Pr√©diction de Prix")

## **1Ô∏è‚É£ Pr√©sentation de l'√âtude**
st.write(
    "Dans le cadre de ma certification Data Analyst, j'ai r√©alis√© une √©tude de march√© "
    "pour estimer le prix d'une bouteille de vin sur le march√© am√©ricain. L'√©tude comprend :"
)
st.markdown("- **Exploration et nettoyage des donn√©es** üßπ\n"
            "- **Visualisation des tendances** üìä\n"
            "- **Mod√©lisation Machine Learning** ü§ñ\n"
            "- **Pr√©diction du prix d'un vin sp√©cifique** üí∞")

# Bouton pour t√©l√©charger le notebook Colab
with open("assets/Florent_CRAMETTE_Certification_Data_Analyst_Cas _Pratiques.ipynb", "rb") as f:
    st.download_button(
        label="üì• T√©l√©charger le notebook Colab",
        data=f,
        file_name="Florent_CRAMETTE_Certification_Data_Analyst_Cas_Pratiques.ipynb",
        mime="application/octet-stream"
    )

## **2Ô∏è‚É£ Chargement et exploration des donn√©es**
@st.cache_data
def load_data():
    df = pd.read_csv("assets/df_wine_filled.csv")  # Mise √† jour du chemin
    return df

df = load_data()

st.subheader("üìå Aper√ßu du Dataset")
st.write(df.head())

## **3Ô∏è‚É£ Nettoyage et am√©lioration des donn√©es**
st.subheader("üßπ Nettoyage des Donn√©es")
st.write("Avant d'entra√Æner notre mod√®le, nous avons proc√©d√© aux √©tapes suivantes :")
st.markdown("- Suppression des colonnes non pertinentes (ex: `taster_name`, `taster_twitter_handle`).\n"
            "- Remplissage des valeurs manquantes :\n"
            "  - Si la province est absente, elle est remplac√©e par `Inconnu`.\n"
            "  - Si le prix est manquant, suppression de la ligne (trop critique).\n"
            "- Encodage des variables cat√©goriques pour la mod√©lisation.")

st.write("Voici les valeurs manquantes par colonne apr√®s nettoyage :")
st.write(df.isnull().sum())

# Suppression des valeurs nulles dans la colonne 'price'
df = df.dropna(subset=['price'])

# Affichage de la heatmap des valeurs nulles
with st.container():
    st.subheader("üó∫Ô∏è Carte des Valeurs Manquantes")
    fig, ax = plt.subplots(figsize=(2, 1.5))
    sns.heatmap(df.isnull(), cbar=False, cmap="viridis", yticklabels=False)
    ax.set_title("Carte des Valeurs Manquantes")
    st.pyplot(fig)

st.write("üìå Aper√ßu des donn√©es apr√®s nettoyage :")
st.write(df.head())

## **4Ô∏è‚É£ Visualisation des donn√©es**
st.subheader("üìä Distribution des Prix du Vin")
with st.container():
    fig, ax = plt.subplots(figsize=(2, 1.5))
    sns.histplot(df['price'], bins=30, kde=True, ax=ax)
    ax.set_title("R√©partition des prix des vins")
    st.pyplot(fig)

# Affichage du boxplot pour d√©tecter les outliers
st.subheader("üìå Analyse des Prix et Outliers")
with st.container():
    fig, ax = plt.subplots(figsize=(2, 1.5))
    sns.boxplot(x=df['price'], ax=ax)
    ax.set_title("Boxplot des Prix des Vins")
    st.pyplot(fig)

st.write("üí° Les prix du vin pr√©sentent une forte variabilit√©, mais les valeurs √©lev√©es ne doivent pas √™tre consid√©r√©es comme des outliers.")
st.write("Il est courant d'avoir des bouteilles √† prix tr√®s √©lev√© en fonction de la r√©gion et de la raret√© du vin.")

## **5Ô∏è‚É£ Mod√®le Machine Learning pour la pr√©diction du prix**
st.subheader("ü§ñ Mod√©lisation et Pr√©diction du Prix")

# Encodage des variables cat√©goriques
features = ["points", "country", "province", "variety"]
label_encoders = {}
for col in ["country", "province", "variety"]:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

X = df[features]
y = df["price"]

# V√©rification et suppression des valeurs nulles restantes dans 'y'
y = y.dropna()
X = X.loc[y.index]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Choix du mod√®le de ML
model_choice = st.radio("S√©lectionnez un mod√®le de Machine Learning", ["Random Forest", "Gradient Boosting"])

if model_choice == "Random Forest":
    n_estimators = st.slider("Nombre d'arbres (n_estimators)", 10, 200, 50, 10)
    model = RandomForestRegressor(n_estimators=n_estimators, random_state=42, n_jobs=-1)
else:
    learning_rate = st.slider("Taux d'apprentissage (learning_rate)", 0.01, 0.5, 0.1, 0.01)
    n_estimators = st.slider("Nombre d'arbres (n_estimators)", 10, 200, 50, 10)
    model = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, random_state=42)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
st.write(f"**Erreur moyenne absolue du mod√®le :** {mae:.2f} $")

## **6Ô∏è‚É£ Pr√©diction pour un vin sp√©cifique**
st.subheader("üí∞ Pr√©diction du Prix pour le Domaine des Croix 2016 - Corton Gr√®ves")
vin_exemple = pd.DataFrame({
    "points": [94],
    "country": [label_encoders["country"].transform(["France"])[0]],
    "province": [label_encoders["province"].transform(["Burgundy"])[0]],
    "variety": [label_encoders["variety"].transform(["Pinot Noir"])[0]],
})
prix_prevu = model.predict(vin_exemple)[0]
st.success(f"üí≤ Prix estim√© sur le march√© am√©ricain : {prix_prevu:.2f} $")

## **7Ô∏è‚É£ Conclusion et recommandations**
st.write(
    "L'analyse des tendances du march√© et l'utilisation d'un mod√®le robuste de Machine Learning "
    "nous permettent d'obtenir une estimation fiable du prix des vins en fonction de leurs caract√©ristiques. "
    "L'ajout de param√®tres personnalisables permet d'optimiser les performances du mod√®le."
)
